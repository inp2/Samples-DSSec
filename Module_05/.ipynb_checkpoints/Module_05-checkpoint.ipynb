{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/z-EtmaFJieY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/z-EtmaFJieY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mldescrip.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "<img src=\"images/mlexpert.png\">\n",
    "\n",
    "<br />\n",
    "<center><h1>The Machine Learning Process</h1></center>\n",
    "\n",
    "<br />\n",
    "<img src=\"images/mlprocess.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The Problem\n",
    "\n",
    "One of the most critical things to do, is to find out what are the inputs and expected outputs. The following questions must be answered:\n",
    "\n",
    "* What is the main objective? What are we trying to predict?\n",
    "* What are the target features?\n",
    "* What is the input data? Is it available?\n",
    "* What kind of problem are we facing? Binary classification? Clustering?\n",
    "* What is the expected improvement?\n",
    "\n",
    "Not every problem can solved, until we have a working model, we just can make certain hypothesis:\n",
    "\n",
    "* Our outputs can be predicted given the inputs\n",
    "* Our available data is sufficient informative to learn the relationship between the inputs and the outputs\n",
    "\n",
    "Machine learning can only be used to memorize patterns that are present in the data. When using machine learning we are making the assumption that the future will behave like the past, and this isn't always true.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "\n",
    "This step will cascade in how good the model will be, the more and better data that we get, the better our model will perform.\n",
    "\n",
    "If you want to control something it should be observable and in order to achieve success, it is essential to define what is considered success. This measure should be directly aligned with the higher level goals. For example: an intrusion detection system typically measures success `recall`. `recall` is the ability of a model to find all the relevant cases within the data. In intrusion detection, `recall` can be thought as of a model's ablity to find all the malicious intrusions. The other measurement is `precision`. When we increase recall we also decrease `precision`. If we labeled all the intrusions as malicious we would have 100% `recall`, however low `precision`. `Precision` is the ability to the model to identify only the relevant data points. In intrusion detection, label all the intrusions the model classifies are malicious that are not. \n",
    "\n",
    "There are different ways of evaluating our problem depending on our type of problem, we will talk about the types of problem when begin to truly explore machine learning in a security context.\n",
    "\n",
    "After determining the type of problem and the proper evaluation method, we must prepare our dataset. In preparation for the supervised learning set of models we must set apart a portion of the data as the test set.\n",
    "\n",
    "The process would be to train the model with the remaining fraction of the data, tunning its parameters with the test set and evaluating its performance on the test set.\n",
    "\n",
    "The main inconvience of this method is that if there is little data avilable, the validation and test sets will contain so few samples that the tuning and evaluation processes of the model will not be effective.\n",
    "\n",
    "<img src=\"images/prepare.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "Before beginning to train models we should transform our data in a way that the data can be fed into a machine learning model. Some of these methods are similar to what we explored earlier.\n",
    "\n",
    "### Missing Data\n",
    "\n",
    "Missing values are typically represented with Null indicators. The problem is that most algorithms can't handle those missing values so we need to take care of them before feeding data to our models. There are a couple of ways to deal with them:\n",
    "\n",
    "1. Eliminate the samples or features with missing values\n",
    "2. Impute the missing values\n",
    "    * Fit our data and then transform it to estimate them\n",
    "    \n",
    "### Feature Engineering\n",
    "\n",
    "The process of using domain knowledge to create features. The process of feature engineering:\n",
    "1. Brainstorming/testing features\n",
    "2. Deciding what features to create\n",
    "3. Creating features\n",
    "4. Checking how the features work with your model\n",
    "5. Improving your features if needed\n",
    "6. Go back back to brainstorming/creating more features until the work is done\n",
    "\n",
    "### Handling Qualitative Data\n",
    "\n",
    "There are two types we have to deal with, ordinal and nominal. Ordinal features can be sorted (cloth's size: L<M<S). Nominal features don't imply any order (cloth's color: yellow, green, red).\n",
    "\n",
    "The methods to deal with ordinal and nominal features are:\n",
    "* <b>Mapping Ordinal Features</b>: to make sure that the algorithm interprets the ordinal features correctly, we convert the values into integers. This is typically done mapping manually. Example: L:2, M:1, S:0.\n",
    "*<b>Encoding nominal class labels</b>: to perform one-hot encoding, which consists in creating a new dummy feature for each unique value in the nominal feature column. A quick example, if there are three colors (red, yellow, green). We will get three new columns, one for each class. If we have a yellow shirt, it will be sampled as yellow = 1, green = 0, and red = 0.\n",
    "\n",
    "\n",
    "### Feature Scaling \n",
    "\n",
    "The majority of machine learning algorithms perform better when dealing with features that are on the same scale: The common techniques are:\n",
    "\n",
    "* Normalization: it refers to rescaling the features to a range of [0,1], which is a special case of min-max scaling, and apply it to each feature column.\n",
    "\n",
    "* Standardization: it consists of centering the feature columns at mean 0 with standard deviation 1 so that the feature olumns have the same parameters as a standard normal distribution (zero meand and unit variance). It keeps useful information about outliers and makes the algorithms less sensitive to them.\n",
    "\n",
    "### Selecting Meaningful Features\n",
    "\n",
    "This is done to avoid overfitting. Overfitting is a modeling error which occurs when a function is too closely fit to a limited set of data points. This is typically done by reducing the number of features by Principal Component Analysis (PCA) a form of unsupervised machine learning algorithm.\n",
    "\n",
    "PCA identifies patterns in our data based on the correlations between the features. This correlation implies redundancy in our data. The correlated data is not essential for the model to learn its weights appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "### Benchmark Model\n",
    "\n",
    "Develop a benchmark model that serves us as a baseline, to measure the performance of a better and more attuned algorithm.\n",
    "\n",
    "### Choose a Model\n",
    "\n",
    "<img src=\"images/mlmodels.png\">\n",
    "\n",
    "There are alot of different models to choose from below I quickly list a cheatsheet that helps us choose what path to go down.\n",
    "\n",
    "* Clustering: Task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups.\n",
    "\n",
    "* Classification: Identifying to which of a set of categories a new observation belongs, on the basis of a training set of data containing observation whose category membership is known.\n",
    "\n",
    "* Regression: Estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables.\n",
    "\n",
    "* Dimensionality Reduction: The process of reducing the number of random variables under consideration by obtaining a set of principal variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Earlier we talked about evaluation depending on the models, this is where this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy & Improve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not get to all the models in this class, however, we will go through multiple use cases to understand the full machine learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheatsheet\n",
    "\n",
    "<img src=\"images/cheatsheet.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "1. https://towardsdatascience.com/machine-learning-general-process-8f1b510bd8af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
